{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrices(m1, m2, num_reports):\n",
    "    \n",
    "    A = (m1.T @ m2)\n",
    "    B = (m1.sum(0).reshape((m1.shape[1],1)) - A)\n",
    "    B[B==0] = 1\n",
    "    C = (m2.sum(0) - A)\n",
    "    C[C==0] = 1\n",
    "    D = (num_reports-(A+B+C))\n",
    "    \n",
    "    PRR = ((A/B)/(C/D))\n",
    "    Tc = A/(A+B+C)\n",
    "\n",
    "    return {\n",
    "        'A': A,\n",
    "        'B': B,\n",
    "        'C': C,\n",
    "        'D': D,\n",
    "        'PRR': PRR,\n",
    "        'Tc': Tc\n",
    "    }\n",
    "\n",
    "def build_dataframe(matrices, ordered_m1, m1_name, ordered_m2, m2_name, m12label=None, m22label=None, minA=10):\n",
    "    \n",
    "    mask = matrices['A']>=minA\n",
    "    indices = np.where(mask)\n",
    "    dfdata = {}\n",
    "\n",
    "    dfdata[m1_name] = [ordered_m1[i] for i in indices[0]]\n",
    "    if m12label is not None:\n",
    "        dfdata[f\"{m1_name}_label\"] = [m12label.get(ordered_m1[i], i) for i in indices[0]]\n",
    "    \n",
    "    dfdata[m2_name] = [ordered_m2[i] for i in indices[1]]\n",
    "    if m22label is not None:\n",
    "        dfdata[f\"{m2_name}_label\"] = [m22label.get(ordered_m2[i], i) for i in indices[1]]\n",
    "\n",
    "    for key, mat in matrices.items():\n",
    "        dfdata[key] = mat[mask]\n",
    "\n",
    "    return pd.DataFrame(dfdata)\n",
    "\n",
    "def build_merged_dataframe(drugs, reactions, indications, num_reports, drug_names, reaction_names, indication_names, minA):\n",
    "    matrices = compute_matrices(drugs, reactions, num_reports)\n",
    "    drug_rxn = build_dataframe(matrices, drug_names, 'drug', \n",
    "                            reaction_names, 'reaction', minA=minA)\n",
    "    \n",
    "    matrices = compute_matrices(indications, reactions, num_reports)\n",
    "    ind_rxn = build_dataframe(matrices, indication_names, 'indication', reaction_names, 'reaction', minA=minA)\n",
    "    \n",
    "    matrices = compute_matrices(indications, drugs, num_reports)\n",
    "    ind_ing = build_dataframe(matrices, indication_names, 'indication', drug_names, 'drug', minA=minA)\n",
    "    \n",
    "    # build datafraem to look at confounding by indication\n",
    "    ind_keep = ['drug', \n",
    "            'reaction', \n",
    "            'indication',\n",
    "            'PRR_ing_rxn',\n",
    "            'PRR_ind_ing',\n",
    "            'PRR_ind_rxn']\n",
    "    ind_merged = drug_rxn.merge(ind_ing, \n",
    "                                on='drug',\n",
    "                                suffixes=('_ing_rxn', '_ind_ing')\n",
    "                            ).merge(ind_rxn,\n",
    "                                on=('indication', 'reaction',),\n",
    "                                suffixes=('', '_ind_rxn'))\n",
    "\n",
    "    ind_merged.rename(columns={'PRR': 'PRR_ind_rxn'}, inplace=True)\n",
    "    ind_reduced = ind_merged[ind_keep]\n",
    "    \n",
    "    return drug_rxn, ind_rxn, ind_ing, ind_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(output_path, dataset_path, split, dataset_idx=0, exampleid=0, show_plots=False):\n",
    "\n",
    "    final_predictions = np.load(os.path.join(output_path, f'final_predictions_{split}_{dataset_idx}.npy'))\n",
    "    \n",
    "    config_path = os.path.join(dataset_path, 'config.json')\n",
    "    if not os.path.exists(config_path):\n",
    "        raise Exception(f\"No config file found at: {config_path}\")\n",
    "    config = json.load(open(config_path))\n",
    "    \n",
    "    # Get dimensions from config\n",
    "    ndrugs = config['ndrugs']\n",
    "    nreactions = config['nreactions']\n",
    "    nindications = config['nindications']\n",
    "    nreports = config['nreports']\n",
    "    # nexamples = config['nexamples']\n",
    "\n",
    "    # For each prediction, split and reshape\n",
    "    reshaped = final_predictions[exampleid].reshape(nreports, ndrugs+nreactions+nindications)\n",
    "    reactions = reshaped[:,:nreactions]\n",
    "    drugs = reshaped[:,nreactions:(ndrugs+nreactions)]\n",
    "    indications = reshaped[:,(ndrugs+nreactions):]\n",
    "    #print(reactions.shape, drugs.shape, indications.shape)\n",
    "    pred = np.hstack([reactions, drugs, indications])\n",
    "\n",
    "    target_drugs = sp.sparse.load_npz(os.path.join(dataset_path, 'drugs.npz')).toarray()\n",
    "    target_reactions = sp.sparse.load_npz(os.path.join(dataset_path, 'reactions.npz')).toarray()\n",
    "    target_indications = sp.sparse.load_npz(os.path.join(dataset_path, 'datasets', f'{exampleid}_indications.npz')).toarray()\n",
    "    target_reactions_observed = sp.sparse.load_npz(os.path.join(dataset_path, 'datasets', f'{exampleid}_reactions_observed.npz')).toarray()\n",
    "    actual = np.hstack([target_reactions, target_drugs, np.zeros(shape=indications.shape)])\n",
    "\n",
    "    #print(target_reactions.shape, target_drugs.shape, target_indications.shape)\n",
    "    \n",
    "    print(f\"Accuracy\")\n",
    "    print(f\"R, D, I: {(pred==actual).sum()/pred.size}\")\n",
    "    print(f\"   Ones: {(actual[actual==1]==pred[actual==1]).sum()/(actual[actual==1]==1).sum()}\")\n",
    "\n",
    "    print()\n",
    "    newpred = pred[:,:nreactions]\n",
    "    newactual = actual[:,:nreactions]\n",
    "    print(f\"R      : {(newpred==newactual).sum()/newpred.size}\")\n",
    "    print(f\"   Ones: {(newactual[newactual==1]==newpred[newactual==1]).sum()/(newactual[newactual==1]==1).sum()}\")\n",
    "\n",
    "    print()\n",
    "    newpred = pred[:,nreactions:(nreactions+ndrugs)]\n",
    "    newactual = actual[:,nreactions:(nreactions+ndrugs)]\n",
    "    print(f\"   D   : {(newpred==newactual).sum()/newpred.size}\")\n",
    "    print(f\"   Ones: {(newactual[newactual==1]==newpred[newactual==1]).sum()/(newactual[newactual==1]==1).sum()}\")\n",
    "\n",
    "    print()\n",
    "    newpred = pred[:,(nreactions+ndrugs):]\n",
    "    newactual = actual[:,(nreactions+ndrugs):]\n",
    "    print(f\"      I: {(newpred==newactual).sum()/newpred.size}\")\n",
    "    #print(f\"   Ones: {(newactual[newactual==1]==newpred[newactual==1]).sum()/(newactual[newactual==1]==1).sum()}\")\n",
    "    print()\n",
    "    \n",
    "    drug_names = config['drug_names']\n",
    "    reaction_names = config['reaction_names']\n",
    "    indication_names = config[f'dataset_{exampleid}']['indication_names']\n",
    "\n",
    "    drug_rxn_obs, _, _, observed = build_merged_dataframe(target_drugs, target_reactions_observed, target_indications, nreports, drug_names, reaction_names, indication_names, minA=1)\n",
    "    \n",
    "    drug_rxn_factors = json.load(open(os.path.join(dataset_path, 'drug_rxn_factors.json')))\n",
    "    drug_rxn_truth = json.load(open(os.path.join(dataset_path, 'drug_rxn_truth.json')))\n",
    "\n",
    "    drug_rxn_obs['factor'] = [drug_rxn_factors[d][r] for _, (d, r) in drug_rxn_obs[['drug', 'reaction']].iterrows()]\n",
    "    drug_rxn_obs['truth'] = [drug_rxn_truth[d][r] for _, (d, r) in drug_rxn_obs[['drug', 'reaction']].iterrows()]\n",
    "    \n",
    "    statistic = 'PRR'\n",
    "    \n",
    "    print(f\"Observed AUROC: {sklearn.metrics.roc_auc_score(drug_rxn_obs['truth'], drug_rxn_obs[statistic])}\")\n",
    "    print(f\"Observed AUPR : {sklearn.metrics.average_precision_score(drug_rxn_obs['truth'], drug_rxn_obs[statistic])}\")\n",
    "    \n",
    "    print(f\"Ind PRRs greatrer than 10: {(observed['PRR_ind_rxn'] > 10).sum()}\")\n",
    "\n",
    "    # we only care about whent the relationship between the indication and the reaction is high\n",
    "    ind_rxn_high = observed[observed['PRR_ind_rxn'] > 10]\n",
    "    #print(ind_rxn_high.shape)\n",
    "\n",
    "    rho, pval = sp.stats.spearmanr(ind_rxn_high['PRR_ind_ing'], ind_rxn_high['PRR_ing_rxn'])\n",
    "    ymin = 0.5*(ind_rxn_high['PRR_ing_rxn'].min())\n",
    "    ymax = 2*(ind_rxn_high['PRR_ing_rxn'].max())\n",
    "    \n",
    "    if show_plots:\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.title(split)\n",
    "        plt.subplot(2,2,1)\n",
    "        plt.scatter(ind_rxn_high['PRR_ind_ing'], ind_rxn_high['PRR_ing_rxn'], alpha=0.4, label=f\"rho={rho:.2f}, P={pval:.2e}\")\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('PRR(Drug, Indication))')\n",
    "        plt.ylabel('Observed PRR(Drug, Rxn)')\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.legend()\n",
    "        sns.despine()\n",
    "\n",
    "        plt.subplot(2,2,2)\n",
    "    \n",
    "\n",
    "    drug_rxn_corr, _, _, corrected = build_merged_dataframe(target_drugs, reactions, target_indications, nreports, drug_names, reaction_names, indication_names, minA=0)\n",
    "    corrected = corrected.merge(ind_rxn_high, on=('drug', 'reaction', 'indication'), suffixes=('_corrected', '_observed'))\n",
    "    rho, pval = sp.stats.spearmanr(corrected['PRR_ind_ing_observed'], corrected['PRR_ing_rxn_corrected'])\n",
    "\n",
    "    drug_rxn_corr['factor'] = [drug_rxn_factors[d][r] for _, (d, r) in drug_rxn_corr[['drug', 'reaction']].iterrows()]\n",
    "    drug_rxn_corr['truth'] = [drug_rxn_truth[d][r] for _, (d, r) in drug_rxn_corr[['drug', 'reaction']].iterrows()]\n",
    "    \n",
    "    print(f\"Corrected AUROC: {sklearn.metrics.roc_auc_score(drug_rxn_corr['truth'], drug_rxn_corr[statistic])}\")\n",
    "    print(f\"Corrected AUPR : {sklearn.metrics.average_precision_score(drug_rxn_corr['truth'], drug_rxn_corr[statistic])}\")\n",
    "\n",
    "    if show_plots:\n",
    "        plt.scatter(corrected['PRR_ind_ing_observed'], corrected['PRR_ing_rxn_corrected'], alpha=0.4, label=f\"rho={rho:.2f}, P={pval:.2e}\")\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.xlabel('PRR(Drug, Indication))')\n",
    "        plt.ylabel('Corrected PRR(Drug, Rxn)')\n",
    "        plt.legend()\n",
    "        sns.despine()\n",
    "\n",
    "        plt.subplot(2,2,3)\n",
    "        fpr, tpr, _ = sklearn.metrics.roc_curve(drug_rxn_obs['truth'], drug_rxn_obs[statistic])\n",
    "        plt.plot(fpr, tpr, label='Observed')\n",
    "        fpr, tpr, _ = sklearn.metrics.roc_curve(drug_rxn_corr['truth'], drug_rxn_corr[statistic])\n",
    "        plt.plot(fpr, tpr, label='Corrected')\n",
    "        plt.ylabel('TPR')\n",
    "        plt.xlabel('FPR')\n",
    "        plt.legend()\n",
    "        sns.despine()\n",
    "        \n",
    "        plt.subplot(2,2,4)\n",
    "        pr, re, _ = sklearn.metrics.precision_recall_curve(drug_rxn_obs['truth'], drug_rxn_obs[statistic])\n",
    "        plt.plot(re, pr, label='Observed')\n",
    "        pr, re, _ = sklearn.metrics.precision_recall_curve(drug_rxn_corr['truth'], drug_rxn_corr[statistic])\n",
    "        plt.plot(re, pr, label='Corrected')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.legend()\n",
    "        sns.despine()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(split)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 512,\n",
       " 'hidden_dim': 8,\n",
       " 'z_dim': 2,\n",
       " 'epochs': 100,\n",
       " 'lr': 0.001,\n",
       " 'gpu': 3,\n",
       " 'wd': 0.1,\n",
       " 'dataset': ['./data/small_pt0.02_mif2',\n",
       "  './data/small_pt0.03_mif2',\n",
       "  './data/small_pt0.04_mif2',\n",
       "  './data/small_pt0.05_mif2',\n",
       "  './data/small_pt0.06_mif2',\n",
       "  './data/small_pt0.07_mif2',\n",
       "  './data/small_pt0.08_mif2',\n",
       "  './data/small_pt0.09_mif2',\n",
       "  './data/small_pt0.09_mif2_0iF',\n",
       "  './data/small_pt0.09_mif2_0Vs',\n",
       "  './data/small_pt0.09_mif2_0Vt',\n",
       "  './data/small_pt0.09_mif2_1dh',\n",
       "  './data/small_pt0.09_mif2_1eI',\n",
       "  './data/small_pt0.09_mif2_1hk',\n",
       "  './data/small_pt0.09_mif2_3qm',\n",
       "  './data/small_pt0.09_mif2_3Z6',\n",
       "  './data/small_pt0.09_mif2_4ZF',\n",
       "  './data/small_pt0.09_mif2_5Uj',\n",
       "  './data/small_pt0.09_mif2_5vR',\n",
       "  './data/small_pt0.09_mif2_68x',\n",
       "  './data/small_pt0.09_mif2_6eb',\n",
       "  './data/small_pt0.09_mif2_6WE',\n",
       "  './data/small_pt0.09_mif2_743',\n",
       "  './data/small_pt0.09_mif2_7GS',\n",
       "  './data/small_pt0.09_mif2_7vu',\n",
       "  './data/small_pt0.09_mif2_a85',\n",
       "  './data/small_pt0.09_mif2_AbO',\n",
       "  './data/small_pt0.09_mif2_Ahu',\n",
       "  './data/small_pt0.09_mif2_ANL',\n",
       "  './data/small_pt0.09_mif2_B5o',\n",
       "  './data/small_pt0.09_mif2_B9i',\n",
       "  './data/small_pt0.09_mif2_b9k',\n",
       "  './data/small_pt0.09_mif2_BgC',\n",
       "  './data/small_pt0.09_mif2_BKR',\n",
       "  './data/small_pt0.09_mif2_C2T',\n",
       "  './data/small_pt0.09_mif2_ccO',\n",
       "  './data/small_pt0.09_mif2_cUf',\n",
       "  './data/small_pt0.09_mif2_Cwo',\n",
       "  './data/small_pt0.09_mif2_CZ6',\n",
       "  './data/small_pt0.09_mif2_dNL',\n",
       "  './data/small_pt0.09_mif2_e5w',\n",
       "  './data/small_pt0.09_mif2_eWt',\n",
       "  './data/small_pt0.09_mif2_fAl',\n",
       "  './data/small_pt0.09_mif2_fHv',\n",
       "  './data/small_pt0.09_mif2_Gck',\n",
       "  './data/small_pt0.09_mif2_gok',\n",
       "  './data/small_pt0.09_mif2_h0Q',\n",
       "  './data/small_pt0.09_mif2_h9m',\n",
       "  './data/small_pt0.09_mif2_Hcy',\n",
       "  './data/small_pt0.09_mif2_Hr0',\n",
       "  './data/small_pt0.09_mif2_hrI',\n",
       "  './data/small_pt0.09_mif2_I1j',\n",
       "  './data/small_pt0.09_mif2_IaP',\n",
       "  './data/small_pt0.09_mif2_isL',\n",
       "  './data/small_pt0.09_mif2_J5k',\n",
       "  './data/small_pt0.09_mif2_jzq',\n",
       "  './data/small_pt0.09_mif2_kd9',\n",
       "  './data/small_pt0.09_mif2_KNt',\n",
       "  './data/small_pt0.09_mif2_L9x',\n",
       "  './data/small_pt0.09_mif2_LfB',\n",
       "  './data/small_pt0.09_mif2_Llz',\n",
       "  './data/small_pt0.09_mif2_LUO',\n",
       "  './data/small_pt0.09_mif2_mFu',\n",
       "  './data/small_pt0.09_mif2_MkU',\n",
       "  './data/small_pt0.09_mif2_mne',\n",
       "  './data/small_pt0.09_mif2_MyL',\n",
       "  './data/small_pt0.09_mif2_mYO',\n",
       "  './data/small_pt0.09_mif2_n6p',\n",
       "  './data/small_pt0.09_mif2_nAs',\n",
       "  './data/small_pt0.09_mif2_nGY',\n",
       "  './data/small_pt0.09_mif2_nOP',\n",
       "  './data/small_pt0.09_mif2_nSA',\n",
       "  './data/small_pt0.09_mif2_OPt',\n",
       "  './data/small_pt0.09_mif2_oVE',\n",
       "  './data/small_pt0.09_mif2_P5v',\n",
       "  './data/small_pt0.09_mif2_p8b',\n",
       "  './data/small_pt0.09_mif2_p8I',\n",
       "  './data/small_pt0.09_mif2_piW',\n",
       "  './data/small_pt0.09_mif2_ppU',\n",
       "  './data/small_pt0.09_mif2_PT3',\n",
       "  './data/small_pt0.09_mif2_Pw8',\n",
       "  './data/small_pt0.09_mif2_qeY',\n",
       "  './data/small_pt0.09_mif2_QjO',\n",
       "  './data/small_pt0.09_mif2_qnu',\n",
       "  './data/small_pt0.09_mif2_rdF',\n",
       "  './data/small_pt0.09_mif2_rRW',\n",
       "  './data/small_pt0.09_mif2_RvU',\n",
       "  './data/small_pt0.09_mif2_ryV',\n",
       "  './data/small_pt0.09_mif2_s4T',\n",
       "  './data/small_pt0.09_mif2_Skw',\n",
       "  './data/small_pt0.09_mif2_SOr',\n",
       "  './data/small_pt0.09_mif2_Tab',\n",
       "  './data/small_pt0.09_mif2_tHf',\n",
       "  './data/small_pt0.09_mif2_Tqb',\n",
       "  './data/small_pt0.09_mif2_UuN',\n",
       "  './data/small_pt0.09_mif2_UYl',\n",
       "  './data/small_pt0.09_mif2_vZd',\n",
       "  './data/small_pt0.09_mif2_wjX',\n",
       "  './data/small_pt0.09_mif2_WzQ',\n",
       "  './data/small_pt0.09_mif2_xGy',\n",
       "  './data/small_pt0.09_mif2_ytv',\n",
       "  './data/small_pt0.09_mif2_YUO',\n",
       "  './data/small_pt0.09_mif2_Yw1',\n",
       "  './data/small_pt0.09_mif2_yWs',\n",
       "  './data/small_pt0.09_mif2_yXv',\n",
       "  './data/small_pt0.09_mif2_Zcl',\n",
       "  './data/small_pt0.09_mif2_ZGI',\n",
       "  './data/small_pt0.09_mif2_Zmp',\n",
       "  './data/small_pt0.09_mif2_zUW',\n",
       "  './data/small_pt0.1_mif2',\n",
       "  './data/small_pt0.1_mif5'],\n",
       " 'save_dir': './outputs/all_small_as_train',\n",
       " 'val_dataset': './data/medium_pt0.1_mif5'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run_path = os.path.join('..', 'outputs/small_pt0.1_mif2_small_pt0.1_mif5_medium_pt0.1_mif5')\n",
    "run_path = os.path.join('..', './outputs/all_small_as_train')\n",
    "run_config = json.load(open(os.path.join(run_path, 'config.json')))\n",
    "run_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50) (10000, 25) (10000, 30)\n",
      "(10000, 50) (10000, 25) (10000, 30)\n",
      "Accuracy\n",
      "R, D, I: 0.7648838095238095\n",
      "   Ones: 0.6236\n",
      "\n",
      "R      : 0.774948\n",
      "   Ones: 0.4522\n",
      "\n",
      "   D   : 0.463788\n",
      "   Ones: 0.795\n",
      "\n",
      "      I: 0.9990233333333334\n",
      "\n",
      "Observed AUROC: 0.7846217788861181\n",
      "Observed AUPR : 0.2894872886147173\n",
      "Ind PRRs greatrer than 10: 11\n",
      "Corrected AUROC: 0.5557203090641328\n",
      "Corrected AUPR : 0.05574330307299588\n"
     ]
    }
   ],
   "source": [
    "dataset_idx = 1\n",
    "train_dataset_paths = list(map(lambda x: os.path.join('..', x), run_config['dataset']))\n",
    "val_dataset_path = os.path.join('..', run_config['val_dataset'])\n",
    "output_path = os.path.join('..', run_config['save_dir'])\n",
    "\n",
    "evaluate_dataset(output_path, \n",
    "                 dataset_path=train_dataset_paths[dataset_idx], \n",
    "                 split='train', \n",
    "                 dataset_idx=dataset_idx, \n",
    "                 exampleid=0,\n",
    "                 show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50) (10000, 25) (10000, 30)\n",
      "(10000, 50) (10000, 25) (10000, 30)\n",
      "Accuracy\n",
      "R, D, I: 0.7659161904761905\n",
      "   Ones: 0.5268\n",
      "\n",
      "R      : 0.77839\n",
      "   Ones: 0.2908\n",
      "\n",
      "   D   : 0.460068\n",
      "   Ones: 0.7628\n",
      "\n",
      "      I: 1.0\n",
      "\n",
      "Observed AUROC: 0.7994796445329908\n",
      "Observed AUPR : 0.3626603495656726\n",
      "Ind PRRs greatrer than 10: 52\n",
      "Corrected AUROC: 0.4830048608042421\n",
      "Corrected AUPR : 0.11511463418324905\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataset(output_path=output_path, \n",
    "                 dataset_path = \n",
    "                 val_dataset_path, \n",
    "                 split = 'val', \n",
    "                 exampleid=0,\n",
    "                 show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
